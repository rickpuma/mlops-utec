{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e64f74b-ae16-4a86-b06a-00b974c068d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "import sagemaker\n",
    "from sagemaker.workflow.parameters import ParameterInteger\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.fail_step import FailStep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c4deb-e967-49b7-891a-2cda3fd68a21",
   "metadata": {},
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710ee9eb-0778-4b21-b5d4-42bf81b4d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pull, model_training, model_evaluation, model_registration\n",
    "pipeline_name = \"pipeline-train\"\n",
    "role = sagemaker.get_execution_role()\n",
    "instance_type = \"ml.m5.large\"\n",
    "cod_month_start = ParameterInteger(name=\"PeriodoCargaInicio\")\n",
    "cod_month_end = ParameterInteger(name=\"PeriodoCargaFin\")\n",
    "tracking_server_arn = 'arn:aws:sagemaker:us-east-1:635106763104:mlflow-tracking-server/mlops-utec-mlflow-server3'\n",
    "experiment_name = \"pipeline-train-experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd1eb6-4f06-4b7f-bc99-384b6fc4f9c7",
   "metadata": {},
   "source": [
    "# DATA PULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3037ed3b-cff8-490a-a5c3-a845f50965a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_pull_requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_pull_requirements.txt\n",
    "awswrangler==3.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6b0ad0-1479-428f-a620-c4ac24c54510",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"DataPull\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./data_pull_requirements.txt\"\n",
    ")\n",
    "def data_pull(experiment_name: str, run_name: str,\n",
    "              cod_month_start: int, cod_month_end: int) -> tuple[str, str, str]:\n",
    "    import awswrangler as wr\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    TARGET_COL = \"is_fraud\"\n",
    "    query = \"\"\"\n",
    "    WITH TRAIN as\n",
    "    (\n",
    "        SELECT  transaction_id\n",
    "                ,customer_id\n",
    "                ,amount\n",
    "                ,merchant_category\n",
    "                ,merchant_country\n",
    "                ,cast(card_present as int) card_present\n",
    "                ,cast(is_fraud as int) is_fraud\n",
    "                ,cast(date_format(timestamp,'%Y%m') as int) as cod_month\n",
    "                ,COUNT(1) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '1' month PRECEDING AND CURRENT ROW) as trx_vel_last_1mths\n",
    "                ,COUNT(1) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '2' MONTH PRECEDING AND CURRENT ROW) as trx_vel_last_2mths\n",
    "                ,SUM(amount) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '1' MONTH PRECEDING AND CURRENT ROW) as amt_vel_last_1mths\n",
    "                ,SUM(amount) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '2' MONTH PRECEDING AND CURRENT ROW) as amt_vel_last_2mths\n",
    "        FROM    RISK_MANAGEMENT.CREDIT_CARD_TRANSACTIONS\n",
    "        WHERE   is_fraud is not null\n",
    "    )\n",
    "    SELECT  *\n",
    "    FROM    TRAIN\n",
    "    WHERE   cod_month between {} and {}\n",
    "    \"\"\".format(cod_month_start, cod_month_end)\n",
    "    train_s3_path = \"s3://mlops-utec-rpa/fraud-detection/train_data/train.csv\"\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        with mlflow.start_run(run_name=\"DataPull\", nested=True):\n",
    "            df = wr.athena.read_sql_query(sql=query, database=\"risk_management\")\n",
    "            df.to_csv(train_s3_path, index=False)\n",
    "            mlflow.log_input(\n",
    "                mlflow.data.from_pandas(df, train_s3_path,\n",
    "                                        targets=TARGET_COL),\n",
    "                context=\"DataPull\"\n",
    "            )\n",
    "    return train_s3_path, experiment_name, run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eae67c-ec22-4618-bf18-1a63b84be990",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a1e44c-a2f1-4c9a-9231-dbe2a4fa8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training_requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training_requirements.txt\n",
    "mlflow==2.13.2\n",
    "sagemaker-mlflow==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a09b95-69a5-4cf8-8634-7026d3f392ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"ModelTraining\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./model_training_requirements.txt\"\n",
    ")\n",
    "def model_training(train_s3_path: str, experiment_name: str,\n",
    "                   run_id: str) -> tuple[str, str, str, str]:\n",
    "    import pandas as pd\n",
    "    import mlflow\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from xgboost import XGBClassifier\n",
    "    TARGET_COL = \"is_fraud\"\n",
    "    SEED = 42\n",
    "    TRAIN_SPLIT = 0.7\n",
    "    FEATURES = ['card_present', 'trx_vel_last_1mths', 'trx_vel_last_2mths',\n",
    "                'amt_vel_last_1mths', 'amt_vel_last_2mths']\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    df = pd.read_csv(\"s3://mlops-utec-rpa/fraud-detection/train_data/train.csv\")\n",
    "    X = df[FEATURES]\n",
    "    y = df[TARGET_COL]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        train_size=TRAIN_SPLIT,\n",
    "                                                        random_state=SEED)\n",
    "    use_gpu = False\n",
    "    param = dict(\n",
    "        objective=\"binary:logistic\",\n",
    "        max_depth=5,\n",
    "        eta=0.2,\n",
    "        gamma=4,\n",
    "        min_child_weight=6,\n",
    "        subsample=0.7,\n",
    "        tree_method=\"gpu_hist\" if use_gpu else \"hist\",\n",
    "        n_estimators=50\n",
    "    )\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        with mlflow.start_run(run_name=\"ModelTraining\",\n",
    "                              nested=True) as training_run:\n",
    "            training_run_id = training_run.info.run_id\n",
    "            test_s3_path = \"s3://mlops-utec-rpa/fraud-detection/test_data/test.csv\"\n",
    "            df_test = pd.concat([X_test, y_test], axis=1)\n",
    "            df_test.to_csv(test_s3_path, index=False)\n",
    "            mlflow.log_input(\n",
    "                mlflow.data.from_pandas(df_test, test_s3_path,\n",
    "                                        targets=TARGET_COL),\n",
    "                context=\"ModelTraining\"\n",
    "            )\n",
    "            mlflow.xgboost.autolog(\n",
    "                log_input_examples=True,\n",
    "                log_model_signatures=True,\n",
    "                log_models=True,\n",
    "                log_datasets=True,\n",
    "                model_format=\"xgb\",\n",
    "            )\n",
    "            xgb = XGBClassifier(**param)\n",
    "            xgb.fit(X_train, y_train)\n",
    "    return test_s3_path, experiment_name, run_id, training_run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c792f23-b6a4-4b76-b07f-7e9623847add",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48f05087-e9f4-4939-b494-8dfd1b7c79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"ModelEvaluation\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./model_training_requirements.txt\"\n",
    ")\n",
    "def evaluate(\n",
    "    test_s3_path: str,\n",
    "    experiment_name: str,\n",
    "    run_id: str,\n",
    "    training_run_id: str,\n",
    ") -> dict:\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "    TARGET_COL = \"is_fraud\"\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        with mlflow.start_run(run_name=\"ModelEvaluation\", nested=True):\n",
    "            test_df = pd.read_csv(test_s3_path)\n",
    "            model = mlflow.pyfunc.load_model(f\"runs:/{training_run_id}/model\")\n",
    "            results = mlflow.evaluate(\n",
    "                model=model,\n",
    "                data=test_df,\n",
    "                targets=TARGET_COL,\n",
    "                model_type=\"classifier\",\n",
    "                evaluators=[\"default\"],\n",
    "            )\n",
    "            return {\"f1_score\": results.metrics[\"f1_score\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfe09d-12ed-4287-8095-7237f5fcf9f9",
   "metadata": {},
   "source": [
    "# MODEL REGISTRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fef744cd-9e42-44ae-82df-06c5b173d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"ModelRegistration\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./model_training_requirements.txt\"\n",
    ")\n",
    "def register(\n",
    "    pipeline_name: str,\n",
    "    experiment_name: str,\n",
    "    run_id: str,\n",
    "    training_run_id: str,\n",
    "):\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        with mlflow.start_run(run_name=\"ModelRegistration\", nested=True):\n",
    "            mlflow.register_model(f\"runs:/{training_run_id}/model\", pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526f6b4-8eb5-4464-82a1-19e54aefa8f9",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1814aafa-4511-46bd-b2b1-3672bfee2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pull_step = data_pull(experiment_name=experiment_name,\n",
    "                           run_name=ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                           cod_month_start=cod_month_start,\n",
    "                           cod_month_end=cod_month_end)\n",
    "\n",
    "model_training_step = model_training(train_s3_path=data_pull_step[0],\n",
    "                                     experiment_name=data_pull_step[1],\n",
    "                                     run_id=data_pull_step[2])\n",
    "\n",
    "conditional_register_step = ConditionStep(\n",
    "    name=\"ConditionalRegister\",\n",
    "    conditions=[\n",
    "        ConditionGreaterThanOrEqualTo(\n",
    "            left=evaluate(\n",
    "                test_s3_path=model_training_step[0],\n",
    "                experiment_name=model_training_step[1],\n",
    "                run_id=model_training_step[2],\n",
    "                training_run_id=model_training_step[3],\n",
    "            )[\"f1_score\"],\n",
    "            right=0.6,\n",
    "        )\n",
    "    ],\n",
    "    if_steps=[\n",
    "        register(\n",
    "            pipeline_name=pipeline_name,\n",
    "            experiment_name=model_training_step[1],\n",
    "            run_id=model_training_step[2],\n",
    "            training_run_id=model_training_step[3],\n",
    "        )\n",
    "    ],\n",
    "    else_steps=[FailStep(name=\"Fail\",\n",
    "                         error_message=\"Model performance is not good enough\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26a5824-adb6-41bd-9c69-69b639c4c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 08:18:13,435 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/DataPull/2025-06-01-08-18-13-152/function\n",
      "2025-06-01 08:18:13,512 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/DataPull/2025-06-01-08-18-13-152/arguments\n",
      "2025-06-01 08:18:13,812 sagemaker.remote_function INFO     Copied dependencies file at './data_pull_requirements.txt' to '/tmp/tmp4jkf6b_z/data_pull_requirements.txt'\n",
      "2025-06-01 08:18:13,840 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/DataPull/2025-06-01-08-18-13-152/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:13,843 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelTraining/2025-06-01-08-18-13-152/function\n",
      "2025-06-01 08:18:13,916 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelTraining/2025-06-01-08-18-13-152/arguments\n",
      "2025-06-01 08:18:13,979 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmpe1j30u8w/model_training_requirements.txt'\n",
      "2025-06-01 08:18:14,007 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/ModelTraining/2025-06-01-08-18-13-152/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:14,009 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelRegistration/2025-06-01-08-18-13-152/function\n",
      "2025-06-01 08:18:14,089 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelRegistration/2025-06-01-08-18-13-152/arguments\n",
      "2025-06-01 08:18:14,158 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmpdpgefe9v/model_training_requirements.txt'\n",
      "2025-06-01 08:18:14,211 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/ModelRegistration/2025-06-01-08-18-13-152/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:14,213 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelEvaluation/2025-06-01-08-18-13-152/function\n",
      "2025-06-01 08:18:14,271 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelEvaluation/2025-06-01-08-18-13-152/arguments\n",
      "2025-06-01 08:18:14,348 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmpw640so2j/model_training_requirements.txt'\n",
      "2025-06-01 08:18:14,379 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/ModelEvaluation/2025-06-01-08-18-13-152/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:14,705 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/DataPull/2025-06-01-08-18-14-705/function\n",
      "2025-06-01 08:18:14,786 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/DataPull/2025-06-01-08-18-14-705/arguments\n",
      "2025-06-01 08:18:15,077 sagemaker.remote_function INFO     Copied dependencies file at './data_pull_requirements.txt' to '/tmp/tmp2w6yz1_4/data_pull_requirements.txt'\n",
      "2025-06-01 08:18:15,101 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/DataPull/2025-06-01-08-18-14-705/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:15,103 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelTraining/2025-06-01-08-18-14-705/function\n",
      "2025-06-01 08:18:15,181 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelTraining/2025-06-01-08-18-14-705/arguments\n",
      "2025-06-01 08:18:15,272 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmpaxl0jsri/model_training_requirements.txt'\n",
      "2025-06-01 08:18:15,306 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/ModelTraining/2025-06-01-08-18-14-705/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:15,310 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelRegistration/2025-06-01-08-18-14-705/function\n",
      "2025-06-01 08:18:15,378 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelRegistration/2025-06-01-08-18-14-705/arguments\n",
      "2025-06-01 08:18:15,436 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmpwhwh29m1/model_training_requirements.txt'\n",
      "2025-06-01 08:18:15,459 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/ModelRegistration/2025-06-01-08-18-14-705/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-01 08:18:15,463 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelEvaluation/2025-06-01-08-18-14-705/function\n",
      "2025-06-01 08:18:15,556 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-train/ModelEvaluation/2025-06-01-08-18-14-705/arguments\n",
      "2025-06-01 08:18:15,628 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmp4lk75jr2/model_training_requirements.txt'\n",
      "2025-06-01 08:18:15,654 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-train/ModelEvaluation/2025-06-01-08-18-14-705/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:635106763104:pipeline/pipeline-train',\n",
       " 'ResponseMetadata': {'RequestId': '329f02fd-00bb-4f9f-845d-f2046073a2e7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '329f02fd-00bb-4f9f-845d-f2046073a2e7',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Sun, 01 Jun 2025 08:18:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(name=pipeline_name,\n",
    "                    steps=[data_pull_step, model_training_step,\n",
    "                           conditional_register_step],\n",
    "                    parameters=[cod_month_start, cod_month_end])\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a16eec8-8a74-4cdc-99d9-9f5291ebb63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:635106763104:pipeline/pipeline-train/execution/agn7atl60u19', sagemaker_session=<sagemaker.session.Session object at 0x7fd040aabfe0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.start(parameters={\"PeriodoCargaInicio\": 202410,\n",
    "                           \"PeriodoCargaFin\": 202412},\n",
    "               execution_display_name=\"test-train-full\",\n",
    "               execution_description=\"Testando training full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e793a-7882-4a82-9f27-664d1f38f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n",
    "execution.describe()\n",
    "execution.wait()\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a0743-7f87-4770-9939-2f1b7625c2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
