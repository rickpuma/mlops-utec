{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e64f74b-ae16-4a86-b06a-00b974c068d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "import sagemaker\n",
    "from sagemaker.workflow.parameters import ParameterInteger\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c4deb-e967-49b7-891a-2cda3fd68a21",
   "metadata": {},
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ee9eb-0778-4b21-b5d4-42bf81b4d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"pipeline-inference\"\n",
    "role = sagemaker.get_execution_role()\n",
    "instance_type = \"ml.m5.large\"\n",
    "cod_month = ParameterInteger(name=\"PeriodoCarga\")\n",
    "tracking_server_arn = 'arn:aws:sagemaker:us-east-1:654654589924:mlflow-tracking-server/mlops-utec-mlflow-server'\n",
    "experiment_name = \"pipeline-inference-experiment\"\n",
    "model_name = \"credit-card-fraud-detection\"\n",
    "model_version = \"latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd1eb6-4f06-4b7f-bc99-384b6fc4f9c7",
   "metadata": {},
   "source": [
    "# DATA PULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3037ed3b-cff8-490a-a5c3-a845f50965a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_pull_requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_pull_requirements.txt\n",
    "awswrangler==3.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6b0ad0-1479-428f-a620-c4ac24c54510",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"DataPull\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./data_pull_requirements.txt\"\n",
    ")\n",
    "def data_pull(experiment_name: str, run_name: str,\n",
    "              cod_month: int) -> tuple[str, str, str]:\n",
    "    import awswrangler as wr\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    query = \"\"\"\n",
    "    WITH TRAIN as\n",
    "    (\n",
    "        SELECT  transaction_id\n",
    "                ,customer_id\n",
    "                ,amount\n",
    "                ,merchant_category\n",
    "                ,merchant_country\n",
    "                ,cast(card_present as int) card_present\n",
    "                ,cast(is_fraud as int) is_fraud\n",
    "                ,cast(date_format(timestamp,'%Y%m') as int) as cod_month\n",
    "                ,COUNT(1) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '1' month PRECEDING AND CURRENT ROW) as trx_vel_last_1mths\n",
    "                ,COUNT(1) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '2' MONTH PRECEDING AND CURRENT ROW) as trx_vel_last_2mths\n",
    "                ,SUM(amount) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '1' MONTH PRECEDING AND CURRENT ROW) as amt_vel_last_1mths\n",
    "                ,SUM(amount) OVER(PARTITION BY customer_id ORDER BY timestamp RANGE BETWEEN INTERVAL '2' MONTH PRECEDING AND CURRENT ROW) as amt_vel_last_2mths\n",
    "        FROM    RISK_MANAGEMENT.CREDIT_CARD_TRANSACTIONS\n",
    "        WHERE   is_fraud is not null\n",
    "    )\n",
    "    SELECT  *\n",
    "    FROM    TRAIN\n",
    "    WHERE   cod_month = {}\n",
    "    \"\"\".format(cod_month)\n",
    "\n",
    "    inf_raw_s3_path = f\"s3://mlops-utec-rpa/fraud-detection/inf-raw-data/{cod_month}.csv\"\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        with mlflow.start_run(run_name=\"DataPull\", nested=True):\n",
    "            df = wr.athena.read_sql_query(sql=query, database=\"risk_management\")\n",
    "            df.to_csv(inf_raw_s3_path, index=False)\n",
    "            mlflow.log_input(\n",
    "                mlflow.data.from_pandas(df, inf_raw_s3_path),\n",
    "                context=\"DataPull\"\n",
    "            )\n",
    "    return inf_raw_s3_path, experiment_name, run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eae67c-ec22-4618-bf18-1a63b84be990",
   "metadata": {},
   "source": [
    "# MODEL INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a1e44c-a2f1-4c9a-9231-dbe2a4fa8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training_requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training_requirements.txt\n",
    "mlflow==2.13.2\n",
    "sagemaker-mlflow==0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25a09b95-69a5-4cf8-8634-7026d3f392ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"ModelInference\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./model_training_requirements.txt\"\n",
    ")\n",
    "def model_inference(inf_raw_s3_path: str, experiment_name: str,\n",
    "                    run_id: str, cod_month: int) -> tuple[str, str, str]:\n",
    "    import pandas as pd\n",
    "    import mlflow\n",
    "\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    FEATURES = ['card_present', 'trx_vel_last_1mths', 'trx_vel_last_2mths',\n",
    "                'amt_vel_last_1mths', 'amt_vel_last_2mths']\n",
    "    model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "    df = pd.read_csv(inf_raw_s3_path)\n",
    "    X = df[FEATURES]\n",
    "    model = mlflow.xgboost.load_model(model_uri)\n",
    "    df[\"prob\"] = model.predict_proba(X)[:, 1]\n",
    "    inf_proc_s3_path = f\"s3://mlops-utec-rpa/fraud-detection/inf-proc-data/{cod_month}.csv\"\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        with mlflow.start_run(run_name=\"ModelInference\", nested=True):\n",
    "            df.to_csv(inf_proc_s3_path, index=False)\n",
    "            mlflow.log_input(\n",
    "                mlflow.data.from_pandas(df, inf_proc_s3_path),\n",
    "                context=\"ModelInference\"\n",
    "            )\n",
    "    return inf_proc_s3_path, experiment_name, run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c792f23-b6a4-4b76-b07f-7e9623847add",
   "metadata": {},
   "source": [
    "# DATA PUSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f05087-e9f4-4939-b494-8dfd1b7c79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(\n",
    "    name=\"DataPush\",\n",
    "    instance_type=instance_type,\n",
    "    dependencies=\"./data_pull_requirements.txt\"\n",
    ")\n",
    "def data_push(inf_proc_s3_path: str,experiment_name: str,run_id: str, cod_month: int):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import mlflow\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import pytz\n",
    "    import awswrangler as wr\n",
    "\n",
    "    ID_COL = \"transaction_id\"\n",
    "    TIME_COL = \"cod_month\"\n",
    "    PRED_COL = \"prob\"\n",
    "    mlflow.set_tracking_uri(tracking_server_arn)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    df = pd.read_csv(inf_proc_s3_path)\n",
    "    df['fraud_profile'] = np.where(df[PRED_COL] >= 0.415, 'High risk',\n",
    "                                   np.where(df[PRED_COL] >= 0.285, 'Medium risk',\n",
    "                                   'Low risk'))\n",
    "\n",
    "    df['model'] = model_name\n",
    "    timezone = pytz.timezone(\"America/Lima\")\n",
    "    df['load_date'] = datetime.now(timezone).strftime(\"%Y%m%d\")\n",
    "    df['order'] = df.prob.rank(method='first', ascending=False).astype(int)\n",
    "\n",
    "    inf_posproc_s3_path = \"s3://mlops-utec-rpa/fraud-detection/inf-posproc-data\"\n",
    "    inf_posproc_s3_path_partition = inf_posproc_s3_path + f'/{TIME_COL}={cod_month}/output.parquet'\n",
    "    database = 'risk_management'\n",
    "    table_name = database + '.fraud_detection'\n",
    "\n",
    "    # Pushing data to S3 path\n",
    "    df = df[[ID_COL, PRED_COL, 'model','fraud_profile','load_date', 'order', TIME_COL]] \n",
    "    df.to_parquet(inf_posproc_s3_path_partition, engine='pyarrow', compression='snappy')\n",
    "\n",
    "    # Creating table\n",
    "    ddl = f\"\"\"\n",
    "    CREATE EXTERNAL TABLE IF NOT EXISTS {table_name} (\n",
    "    {ID_COL} string,\n",
    "    {PRED_COL} double,\n",
    "    model string,\n",
    "    fraud_profile string,\n",
    "    load_date string,\n",
    "    order int\n",
    "    )\n",
    "    PARTITIONED BY ({TIME_COL} int)\n",
    "    STORED AS parquet\n",
    "    LOCATION '{inf_posproc_s3_path}'\n",
    "    TBLPROPERTIES ('parquet.compression'='SNAPPY')\n",
    "    \"\"\"\n",
    "    query_exec_id = wr.athena.start_query_execution(sql=ddl, database=database)\n",
    "    wr.athena.wait_query(query_execution_id=query_exec_id)\n",
    "\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        with mlflow.start_run(run_name=\"DataPush\", nested=True):\n",
    "                mlflow.log_input(\n",
    "                mlflow.data.from_pandas(df, inf_posproc_s3_path_partition),\n",
    "                context=\"DataPush\"\n",
    "            )\n",
    "    # Refreshing partition\n",
    "    dml = f\"MSCK REPAIR TABLE {table_name}\"\n",
    "    query_exec_id = wr.athena.start_query_execution(sql=dml, database=database)\n",
    "    wr.athena.wait_query(query_execution_id=query_exec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526f6b4-8eb5-4464-82a1-19e54aefa8f9",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1814aafa-4511-46bd-b2b1-3672bfee2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pull_step = data_pull(experiment_name=experiment_name,\n",
    "                           run_name=ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                           cod_month=cod_month)\n",
    "\n",
    "model_inference_step = model_inference(inf_raw_s3_path=data_pull_step[0],\n",
    "                                     experiment_name=data_pull_step[1],\n",
    "                                     run_id=data_pull_step[2],\n",
    "                                       cod_month=cod_month)\n",
    "\n",
    "data_push_step = data_push(inf_proc_s3_path=model_inference_step[0],\n",
    "                                     experiment_name=model_inference_step[1],\n",
    "                                     run_id=model_inference_step[2],\n",
    "                                      cod_month=cod_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26a5824-adb6-41bd-9c69-69b639c4c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 03:49:09,719 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPull/2025-06-02-03-49-09-458/function\n",
      "2025-06-02 03:49:09,790 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPull/2025-06-02-03-49-09-458/arguments\n",
      "2025-06-02 03:49:10,117 sagemaker.remote_function INFO     Copied dependencies file at './data_pull_requirements.txt' to '/tmp/tmph8a9fl_z/data_pull_requirements.txt'\n",
      "2025-06-02 03:49:10,162 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPull/2025-06-02-03-49-09-458/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-02 03:49:10,165 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-inference/ModelInference/2025-06-02-03-49-09-458/function\n",
      "2025-06-02 03:49:10,241 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-inference/ModelInference/2025-06-02-03-49-09-458/arguments\n",
      "2025-06-02 03:49:10,331 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmptrqflln4/model_training_requirements.txt'\n",
      "2025-06-02 03:49:10,354 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-inference/ModelInference/2025-06-02-03-49-09-458/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-02 03:49:10,357 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPush/2025-06-02-03-49-09-458/function\n",
      "2025-06-02 03:49:10,457 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPush/2025-06-02-03-49-09-458/arguments\n",
      "2025-06-02 03:49:10,537 sagemaker.remote_function INFO     Copied dependencies file at './data_pull_requirements.txt' to '/tmp/tmp9p8y4bch/data_pull_requirements.txt'\n",
      "2025-06-02 03:49:10,562 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPush/2025-06-02-03-49-09-458/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-02 03:49:11,003 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPull/2025-06-02-03-49-11-003/function\n",
      "2025-06-02 03:49:11,080 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPull/2025-06-02-03-49-11-003/arguments\n",
      "2025-06-02 03:49:11,368 sagemaker.remote_function INFO     Copied dependencies file at './data_pull_requirements.txt' to '/tmp/tmpz66ml415/data_pull_requirements.txt'\n",
      "2025-06-02 03:49:11,397 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPull/2025-06-02-03-49-11-003/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-02 03:49:11,400 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-inference/ModelInference/2025-06-02-03-49-11-003/function\n",
      "2025-06-02 03:49:11,465 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-inference/ModelInference/2025-06-02-03-49-11-003/arguments\n",
      "2025-06-02 03:49:11,529 sagemaker.remote_function INFO     Copied dependencies file at './model_training_requirements.txt' to '/tmp/tmpeodgn6nr/model_training_requirements.txt'\n",
      "2025-06-02 03:49:11,561 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-inference/ModelInference/2025-06-02-03-49-11-003/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-06-02 03:49:11,563 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPush/2025-06-02-03-49-11-003/function\n",
      "2025-06-02 03:49:11,623 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPush/2025-06-02-03-49-11-003/arguments\n",
      "2025-06-02 03:49:11,695 sagemaker.remote_function INFO     Copied dependencies file at './data_pull_requirements.txt' to '/tmp/tmppyv9ynr2/data_pull_requirements.txt'\n",
      "2025-06-02 03:49:11,719 sagemaker.remote_function INFO     Successfully uploaded dependencies and pre execution scripts to 's3://sagemaker-us-east-1-635106763104/pipeline-inference/DataPush/2025-06-02-03-49-11-003/pre_exec_script_and_dependencies'\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:635106763104:pipeline/pipeline-inference',\n",
       " 'ResponseMetadata': {'RequestId': 'ba6c4b9e-e0b7-4db6-8d9e-bea5fab43155',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ba6c4b9e-e0b7-4db6-8d9e-bea5fab43155',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '86',\n",
       "   'date': 'Mon, 02 Jun 2025 03:49:12 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(name=pipeline_name,\n",
    "                    steps=[data_pull_step, model_inference_step,data_push_step],\n",
    "                    parameters=[cod_month])\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a16eec8-8a74-4cdc-99d9-9f5291ebb63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:us-east-1:635106763104:pipeline/pipeline-inference/execution/8qem1zji5ut5', sagemaker_session=<sagemaker.session.Session object at 0x7fec8454a180>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.start(parameters={\"PeriodoCarga\": 202501},\n",
    "               execution_display_name=\"test-inference-full2\",\n",
    "               execution_description=\"Testando inferece full2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e793a-7882-4a82-9f27-664d1f38f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution = pipeline.start()\n",
    "# execution.describe()\n",
    "# execution.wait()\n",
    "# execution.list_steps()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
